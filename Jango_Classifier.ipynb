{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jango Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4-DAJaRAEBG",
        "outputId": "eb40b3f4-b85f-465f-e0c8-f96e0001fee9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqGaMES_Wu6u"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import conv2d,max_pool2d,log_softmax,linear,relu,dropout2d\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afl1K9nVsxw6"
      },
      "source": [
        "train_dataset=\"/content/drive/MyDrive/jackfruit_mango_classifier/training_new_trial\"\n",
        "test_dataset=\"/content/drive/MyDrive/jackfruit_mango_classifier/test_set\"\n",
        "valid_dataset=\"/content/drive/My Drive/jackfruit_mango_classifier/validation\"\n",
        "train_set =\"/content/drive/MyDrive/jackfruit_mango_classifier/training_new_trial\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RIiR7xmiA1"
      },
      "source": [
        "#data = pd.read_csv(r'/content/drive/MyDrive/jackfruit_mango_classifier/combined/training_data.csv')\n",
        "#data.head()\n",
        "#data.tail()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-49JRxIk6Z28"
      },
      "source": [
        "typing out code to get label auto matically use when required by copying to code cell\n",
        "dataset = ImageFolder(r'/content/drive/MyDrive/jackfruit_mango_classifier/training_set/training_data.csv',transform = ToTensor)\n",
        "img,label= dataset[0]\n",
        "print(dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZvvEn0qMIo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ebf82d-45fa-42ba-81dc-79d9da576087"
      },
      "source": [
        "#typing out code to get label auto matically use when required by copying to code cell\n",
        "mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float)\n",
        "std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float)\n",
        "transform1 = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)])\n",
        "train_data = ImageFolder(r'/content/drive/MyDrive/jackfruit_mango_classifier/training_new_trial/',transform = transform1)\n",
        "img,label= train_data[1]\n",
        "print(img.shape)\n",
        "print(train_data[0])\n",
        "print(train_data.classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "(tensor([[[ 0.2282, -0.0629, -0.2342,  ...,  1.5468,  1.5810,  1.8037],\n",
            "         [ 0.0912, -0.1999, -0.2171,  ...,  1.1187,  1.1015,  1.3927],\n",
            "         [ 0.1254, -0.2342, -0.1657,  ...,  0.7591,  0.7762,  1.1187],\n",
            "         ...,\n",
            "         [ 1.3242, -0.2856, -0.9020,  ...,  1.1529,  1.1529,  1.4269],\n",
            "         [ 0.9303,  0.3309, -0.8678,  ...,  0.6734,  0.4508,  1.4269],\n",
            "         [ 0.2624, -0.1999,  0.3652,  ..., -0.2342, -0.4397,  1.2557]],\n",
            "\n",
            "        [[ 0.3102,  0.0301, -0.1800,  ...,  1.4307,  1.1506,  1.6583],\n",
            "         [ 0.2052, -0.0749, -0.1625,  ...,  0.9055,  0.5553,  1.0455],\n",
            "         [ 0.1877, -0.1275, -0.1275,  ...,  0.4678,  0.1527,  0.6604],\n",
            "         ...,\n",
            "         [ 1.3431, -0.2150, -0.8452,  ...,  1.4482,  1.4832,  1.6232],\n",
            "         [ 0.9930,  0.3803, -0.8803,  ...,  0.9405,  0.7829,  1.6232],\n",
            "         [ 0.3277, -0.1625,  0.3627,  ..., -0.1975, -0.3025,  1.4657]],\n",
            "\n",
            "        [[ 0.8448,  0.5659,  0.3045,  ...,  1.2108,  0.5834,  1.4897],\n",
            "         [ 0.7228,  0.4439,  0.2871,  ...,  0.5659, -0.0790,  0.7402],\n",
            "         [ 0.6531,  0.3742,  0.3219,  ...,  0.0256, -0.4624,  0.3393],\n",
            "         ...,\n",
            "         [ 0.9494, -0.0267, -0.4101,  ...,  1.7860,  1.7685,  1.7685],\n",
            "         [ 0.3742, -0.0615, -0.6715,  ...,  1.0365,  0.6531,  1.5420],\n",
            "         [ 0.6531, -0.0092,  0.3393,  ..., -0.2358, -0.4973,  1.0714]]]), 0)\n",
            "['chakka', 'manga']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2CkUrrn7y4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab371bd3-7392-4b13-e8e8-0b620bbb0717"
      },
      "source": [
        "valid_data = ImageFolder(r'/content/drive/MyDrive/jackfruit_mango_classifier/validation/',transform = transform1)\n",
        "img,label= valid_data[0]\n",
        "print(valid_data[0])\n",
        "print(valid_data.classes)\n",
        "print(img.shape,img.type)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[-1.7754, -1.8782, -1.5870,  ..., -0.5082, -0.2856, -0.4911],\n",
            "         [-1.6555, -1.7240, -1.5014,  ..., -0.7650, -0.5596, -0.5767],\n",
            "         [-1.6384, -1.7754, -1.6555,  ..., -0.7137, -0.4226, -0.3198],\n",
            "         ...,\n",
            "         [-1.4329, -1.4843, -1.5699,  ..., -0.5596, -0.9363, -1.2445],\n",
            "         [-1.5699, -1.6042, -1.6727,  ..., -0.4226, -0.9705, -1.1418],\n",
            "         [-1.6213, -1.6898, -1.7069,  ..., -0.4226, -1.0904, -1.0390]],\n",
            "\n",
            "        [[-1.8431, -1.8957, -1.6681,  ..., -0.6527, -0.4251, -0.6176],\n",
            "         [-1.7381, -1.7906, -1.6506,  ..., -0.8452, -0.6352, -0.6527],\n",
            "         [-1.7381, -1.8431, -1.7906,  ..., -0.8452, -0.5126, -0.4251],\n",
            "         ...,\n",
            "         [-1.5805, -1.6155, -1.6681,  ..., -0.7927, -1.1604, -1.3880],\n",
            "         [-1.6681, -1.6856, -1.7206,  ..., -0.6877, -1.2129, -1.3179],\n",
            "         [-1.6856, -1.7381, -1.7556,  ..., -0.6877, -1.2654, -1.1779]],\n",
            "\n",
            "        [[-1.7522, -1.7696, -1.6650,  ..., -0.7936, -0.5844, -0.7587],\n",
            "         [-1.6999, -1.7173, -1.6650,  ..., -0.9330, -0.7064, -0.7238],\n",
            "         [-1.6999, -1.7522, -1.7347,  ..., -0.9504, -0.6193, -0.5495],\n",
            "         ...,\n",
            "         [-1.5953, -1.6127, -1.6302,  ..., -0.9853, -1.2990, -1.4210],\n",
            "         [-1.6302, -1.6476, -1.6650,  ..., -0.9504, -1.3513, -1.4036],\n",
            "         [-1.6302, -1.6650, -1.6824,  ..., -0.9678, -1.4036, -1.2816]]]), 0)\n",
            "['chakka', 'maanga']\n",
            "torch.Size([3, 32, 32]) <built-in method type of Tensor object at 0x7facebd77fa0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIoAgI-nwaha"
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(train_set, transform=transform1)\n",
        "\n",
        "# Create a Train DataLoader using Train Dataset\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=5,\n",
        "    shuffle=False,\n",
        "    #num_workers=0\n",
        ")\n",
        "# Create a Test DataLoader using Test Dataset\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=5,\n",
        "    shuffle=False,\n",
        "    #num_workers=0\n",
        ")\n",
        "val_data_loader = torch.utils.data.DataLoader(\n",
        "    dataset = valid_data, \n",
        "    batch_size = 5, \n",
        "    shuffle=False, \n",
        "    #num_workers=0\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MNUfFaVWoGa"
      },
      "source": [
        "#architecture based on Lenet\n",
        "class newmodel(nn.Module):\n",
        "  #defining basic layers\n",
        "  def __init__(self):\n",
        "    super(newmodel, self).__init__()\n",
        "    self.conv1=nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "    self.pool= nn.MaxPool2d(2,2)\n",
        "    self.conv2=nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    self.fully_connected1=nn.Linear(400,120)\n",
        "    self.fully_connected2 =nn.Linear(120,84)\n",
        "    self.fully_connected3=nn.Linear(84,2)\n",
        "    self.drop=nn.Dropout2d()\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.pool(relu(self.conv1(x)))\n",
        "    x=self.pool(relu(self.conv2(x)))\n",
        "  # print(x.shape)\n",
        "    x = x.view(x.shape[0],-1) \n",
        "  #  print(x.shape)\n",
        "    x=relu(self.fully_connected1(x))\n",
        "    x=relu(self.fully_connected2(x))\n",
        "    #x=self.drop(x)\n",
        "    x=((self.fully_connected3(x))) \n",
        "    return x\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vk0j8XwYj1r",
        "outputId": "85888c89-dc62-408e-b1dc-08d16f4e7284"
      },
      "source": [
        "model = newmodel()\n",
        "print(model)\n",
        "model_save_name = 'jango_classifier.pt'\n",
        "path_model = \"/content/drive/MyDrive/jackfruit_mango_classifier/\" + model_save_name\n",
        "model.load_state_dict(torch.load(path_model))\n",
        "print(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmodel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fully_connected1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fully_connected2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fully_connected3): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (drop): Dropout2d(p=0.5, inplace=False)\n",
            ")\n",
            "newmodel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fully_connected1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fully_connected2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fully_connected3): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (drop): Dropout2d(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQyZplj2-j3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc5sQ2k53Alz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0562d047-5c8b-4cf4-9a7f-6d5f97764f39"
      },
      "source": [
        "#model = newmodel()\n",
        "print(model)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "else:\n",
        "    model.cpu()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmodel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fully_connected1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fully_connected2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fully_connected3): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (drop): Dropout2d(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC16pBQo3TRX"
      },
      "source": [
        "#loss function and optimiser\n",
        "epochs = 100\n",
        "batch_size = 5\n",
        "learning_rate = 0.01\n",
        "loss_f = torch.nn.NLLLoss()\n",
        "loss_func =nn.CrossEntropyLoss()\n",
        "optimise=torch.optim.Adam(model.parameters(),lr=0.01)\n",
        "#loss_func=loss_func.to(device)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d549klqBiyco"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9onwWSwizCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d018e0-5d58-460b-82b8-7c72366824dc"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-9trmcIjmPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccceb47d-dad1-42ae-c206-8cfcdbfa3d51"
      },
      "source": [
        "#training and testing\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "accuracy = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  trainloss=0\n",
        "  validloss=0\n",
        "\n",
        "  model.train()\n",
        "  for data,label in train_data_loader:\n",
        "    #print(data.shape)\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "    #print(label.shape)\n",
        "    #to clear gradients\n",
        "    optimise.zero_grad()\n",
        "    output = model(data)\n",
        "   # print(output)\n",
        "    loss = loss_func(output,label)\n",
        "    loss.backward()\n",
        "    optimise.step()\n",
        "    trainloss += loss.item() #.item to convert to float\n",
        "    train_loss.append(trainloss)\n",
        "    #accuracy.append((label==np.argmax(output)).sum().item() / label.shape[0])\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "  for data,label in val_data_loader:\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "    output = model(data)\n",
        "    loss = loss_func(output,label)\n",
        "    validloss += loss.item() \n",
        "    val_loss.append(validloss)\n",
        "    accuracy.append((label==torch.argmax(output.data,1)).sum().item() / label.shape[0])\n",
        "\n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t valid_accuracy: {:.2f}'.format(epoch, trainloss, validloss,sum(accuracy)/len(accuracy)))\n",
        "    \n",
        "  torch.save(model.state_dict(), '/content/drive/MyDrive/jackfruit_mango_classifier/model.ckpt')\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 78.121905 \tValidation Loss: 3.184111 \t valid_accuracy: 0.50\n",
            "Epoch: 1 \tTraining Loss: 80.586682 \tValidation Loss: 3.307491 \t valid_accuracy: 0.50\n",
            "Epoch: 2 \tTraining Loss: 81.752412 \tValidation Loss: 3.349154 \t valid_accuracy: 0.50\n",
            "Epoch: 3 \tTraining Loss: 82.157848 \tValidation Loss: 3.363000 \t valid_accuracy: 0.50\n",
            "Epoch: 4 \tTraining Loss: 82.296102 \tValidation Loss: 3.367737 \t valid_accuracy: 0.50\n",
            "Epoch: 5 \tTraining Loss: 82.345603 \tValidation Loss: 3.369499 \t valid_accuracy: 0.50\n",
            "Epoch: 6 \tTraining Loss: 82.365671 \tValidation Loss: 3.370272 \t valid_accuracy: 0.50\n",
            "Epoch: 7 \tTraining Loss: 82.375648 \tValidation Loss: 3.370697 \t valid_accuracy: 0.50\n",
            "Epoch: 8 \tTraining Loss: 82.381877 \tValidation Loss: 3.370985 \t valid_accuracy: 0.50\n",
            "Epoch: 9 \tTraining Loss: 82.386449 \tValidation Loss: 3.371208 \t valid_accuracy: 0.50\n",
            "Epoch: 10 \tTraining Loss: 82.390135 \tValidation Loss: 3.371390 \t valid_accuracy: 0.50\n",
            "Epoch: 11 \tTraining Loss: 82.393211 \tValidation Loss: 3.371546 \t valid_accuracy: 0.50\n",
            "Epoch: 12 \tTraining Loss: 82.395842 \tValidation Loss: 3.371678 \t valid_accuracy: 0.50\n",
            "Epoch: 13 \tTraining Loss: 82.398105 \tValidation Loss: 3.371793 \t valid_accuracy: 0.50\n",
            "Epoch: 14 \tTraining Loss: 82.400061 \tValidation Loss: 3.371892 \t valid_accuracy: 0.50\n",
            "Epoch: 15 \tTraining Loss: 82.401749 \tValidation Loss: 3.371978 \t valid_accuracy: 0.50\n",
            "Epoch: 16 \tTraining Loss: 82.403225 \tValidation Loss: 3.372053 \t valid_accuracy: 0.50\n",
            "Epoch: 17 \tTraining Loss: 82.404506 \tValidation Loss: 3.372118 \t valid_accuracy: 0.50\n",
            "Epoch: 18 \tTraining Loss: 82.405625 \tValidation Loss: 3.372175 \t valid_accuracy: 0.50\n",
            "Epoch: 19 \tTraining Loss: 82.406605 \tValidation Loss: 3.372224 \t valid_accuracy: 0.50\n",
            "Epoch: 20 \tTraining Loss: 82.407458 \tValidation Loss: 3.372267 \t valid_accuracy: 0.50\n",
            "Epoch: 21 \tTraining Loss: 82.408204 \tValidation Loss: 3.372306 \t valid_accuracy: 0.50\n",
            "Epoch: 22 \tTraining Loss: 82.408862 \tValidation Loss: 3.372339 \t valid_accuracy: 0.50\n",
            "Epoch: 23 \tTraining Loss: 82.409438 \tValidation Loss: 3.372368 \t valid_accuracy: 0.50\n",
            "Epoch: 24 \tTraining Loss: 82.409943 \tValidation Loss: 3.372393 \t valid_accuracy: 0.50\n",
            "Epoch: 25 \tTraining Loss: 82.410381 \tValidation Loss: 3.372415 \t valid_accuracy: 0.50\n",
            "Epoch: 26 \tTraining Loss: 82.410773 \tValidation Loss: 3.372435 \t valid_accuracy: 0.50\n",
            "Epoch: 27 \tTraining Loss: 82.411112 \tValidation Loss: 3.372452 \t valid_accuracy: 0.50\n",
            "Epoch: 28 \tTraining Loss: 82.411414 \tValidation Loss: 3.372467 \t valid_accuracy: 0.50\n",
            "Epoch: 29 \tTraining Loss: 82.411681 \tValidation Loss: 3.372481 \t valid_accuracy: 0.50\n",
            "Epoch: 30 \tTraining Loss: 82.411913 \tValidation Loss: 3.372492 \t valid_accuracy: 0.50\n",
            "Epoch: 31 \tTraining Loss: 82.412118 \tValidation Loss: 3.372502 \t valid_accuracy: 0.50\n",
            "Epoch: 32 \tTraining Loss: 82.412297 \tValidation Loss: 3.372511 \t valid_accuracy: 0.50\n",
            "Epoch: 33 \tTraining Loss: 82.412454 \tValidation Loss: 3.372519 \t valid_accuracy: 0.50\n",
            "Epoch: 34 \tTraining Loss: 82.412596 \tValidation Loss: 3.372526 \t valid_accuracy: 0.50\n",
            "Epoch: 35 \tTraining Loss: 82.412722 \tValidation Loss: 3.372532 \t valid_accuracy: 0.50\n",
            "Epoch: 36 \tTraining Loss: 82.412829 \tValidation Loss: 3.372538 \t valid_accuracy: 0.50\n",
            "Epoch: 37 \tTraining Loss: 82.412925 \tValidation Loss: 3.372542 \t valid_accuracy: 0.50\n",
            "Epoch: 38 \tTraining Loss: 82.413009 \tValidation Loss: 3.372546 \t valid_accuracy: 0.50\n",
            "Epoch: 39 \tTraining Loss: 82.413086 \tValidation Loss: 3.372550 \t valid_accuracy: 0.50\n",
            "Epoch: 40 \tTraining Loss: 82.413144 \tValidation Loss: 3.372553 \t valid_accuracy: 0.50\n",
            "Epoch: 41 \tTraining Loss: 82.413208 \tValidation Loss: 3.372556 \t valid_accuracy: 0.50\n",
            "Epoch: 42 \tTraining Loss: 82.413258 \tValidation Loss: 3.372558 \t valid_accuracy: 0.50\n",
            "Epoch: 43 \tTraining Loss: 82.413302 \tValidation Loss: 3.372561 \t valid_accuracy: 0.50\n",
            "Epoch: 44 \tTraining Loss: 82.413343 \tValidation Loss: 3.372562 \t valid_accuracy: 0.50\n",
            "Epoch: 45 \tTraining Loss: 82.413375 \tValidation Loss: 3.372564 \t valid_accuracy: 0.50\n",
            "Epoch: 46 \tTraining Loss: 82.413407 \tValidation Loss: 3.372566 \t valid_accuracy: 0.50\n",
            "Epoch: 47 \tTraining Loss: 82.413439 \tValidation Loss: 3.372567 \t valid_accuracy: 0.50\n",
            "Epoch: 48 \tTraining Loss: 82.413460 \tValidation Loss: 3.372568 \t valid_accuracy: 0.50\n",
            "Epoch: 49 \tTraining Loss: 82.413480 \tValidation Loss: 3.372569 \t valid_accuracy: 0.50\n",
            "Epoch: 50 \tTraining Loss: 82.413498 \tValidation Loss: 3.372570 \t valid_accuracy: 0.50\n",
            "Epoch: 51 \tTraining Loss: 82.413516 \tValidation Loss: 3.372571 \t valid_accuracy: 0.50\n",
            "Epoch: 52 \tTraining Loss: 82.413532 \tValidation Loss: 3.372572 \t valid_accuracy: 0.50\n",
            "Epoch: 53 \tTraining Loss: 82.413548 \tValidation Loss: 3.372572 \t valid_accuracy: 0.50\n",
            "Epoch: 54 \tTraining Loss: 82.413561 \tValidation Loss: 3.372573 \t valid_accuracy: 0.50\n",
            "Epoch: 55 \tTraining Loss: 82.413568 \tValidation Loss: 3.372573 \t valid_accuracy: 0.50\n",
            "Epoch: 56 \tTraining Loss: 82.413578 \tValidation Loss: 3.372574 \t valid_accuracy: 0.50\n",
            "Epoch: 57 \tTraining Loss: 82.413585 \tValidation Loss: 3.372574 \t valid_accuracy: 0.50\n",
            "Epoch: 58 \tTraining Loss: 82.413591 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 59 \tTraining Loss: 82.413595 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 60 \tTraining Loss: 82.413606 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 61 \tTraining Loss: 82.413610 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 62 \tTraining Loss: 82.413612 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 63 \tTraining Loss: 82.413613 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 64 \tTraining Loss: 82.413617 \tValidation Loss: 3.372575 \t valid_accuracy: 0.50\n",
            "Epoch: 65 \tTraining Loss: 82.413620 \tValidation Loss: 3.372576 \t valid_accuracy: 0.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l91iRTSEwm-l"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for data,label in val_data_loader:\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "    print(\"label=\",label)\n",
        "\n",
        "    output = model(data)\n",
        "    print(\"output\",output.data)\n",
        "    predicted = torch.argmax(output.data,1)\n",
        "    print(\"chech\",label,predicted,total,\"iiii\")\n",
        "    total+=1\n",
        "    if (predicted==label):\n",
        "        correct+=1\n",
        "  print('Accuracy:'+ str(100*correct/total))\n",
        "  #return data,predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu4q22Z9IRmP"
      },
      "source": [
        "#saving trained model to drive\n",
        "model_save_name = 'jango_classifier.pt'\n",
        "path_model = \"/content/drive/MyDrive/jackfruit_mango_classifier/\" + model_save_name\n",
        "torch.save(model.state_dict(), path_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Y3G5Vvwiai"
      },
      "source": [
        "#visualise fitting\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(train_loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(frameon=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbgvdrtmYcb"
      },
      "source": [
        "#loading model from drive\n",
        "#model.load_state_dict(torch.load(path_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4wHZgBhITge"
      },
      "source": [
        "#gettimg images from url\n",
        "urll = \"https://thumbs.dreamstime.com/b/fruits-mango-scientific-name-mangifera-indica-anacardiaceae-ripened-fruit-piled-up-sale-thiruvananthapuram-kerala-india-48649430.jpg\"\n",
        "from imageio import imread\n",
        "image = imread(urll)\n",
        "image = Image.fromarray(image)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wnpZgzqnKpk"
      },
      "source": [
        "\n",
        "# model = torch.load('BasicCNN_Pytorch/model_50.pth', map_location=device) \n",
        "# model.eval()\n",
        "\n",
        "class_list ={0:'chakka', 1:'maanga'}\n",
        "detransform= transforms.Compose([\n",
        "    transforms.Normalize(mean = -mean/std, std = 1./std),\n",
        "    transforms.ToPILImage()\n",
        "])\n",
        "transform1 = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "        image=transform1(image)\n",
        "        output = model(image)\n",
        "        output = nn.Softmax(dim=1)(output)[0]*100\n",
        "        \n",
        "        id = output.argmax().data.item()\n",
        "        oclass = list(class_list.keys())[id]\n",
        "        output = output.int().data.cpu().numpy()\n",
        "\n",
        "        display(detransform(image))\n",
        "        print(class_list[oclass], ':', output[id], '%', '\\n\\n')\n",
        "\n",
        "model.train()\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6QvVlIPhZM6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_8815Cqcenm"
      },
      "source": [
        ""
      ]
    }
  ]
}